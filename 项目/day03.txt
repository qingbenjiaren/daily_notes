思考：应该用哪些技术哪些方案构建高并发的系统

	服务降级
		业务场景：
			大促的时间点，网站流量暴增。需要批量关闭边缘服务（不重要的服务），这就是服务降级----做好服务降级，应对一些突发情况
		
		降级预案（并不是所有的系统都需要做降级）
			接口 -- 不可降级：服务非常重要，无法降级			
			接口 -- 重要：严重的问题，降级
			接口 -- 一般降级：可降级，自动降级，人工降级
			接口 -- 可要不可要：敏感型降级
			需要做一些非常精细化的设计
		第三方技术：
			1、sentinel 服务治理
			2、sky walking 链路追踪
			3、appolo 配置中心
		
		降级的处理策略：------> 降级 ------->请求不可达 -------> 减轻后台服务压力，释放更多资源为核心服务进行服务
			
			页面降级（页面访问加载数据 -----> 访问静态页面、缓存页面、数据从缓存中加载，返回一个第三方页面：【亲，现在业务繁忙】）
			延迟服务（延迟消息队列）
			写降级（异步方式进行降级：1、暂时把数据写入缓存，过一段时间再把数据同步到数据库。2、禁止写入数据）
			读降级（1、缓存读  2、禁止读）
			
			后端代码业务降级
			1、抛异常 ----- 阻断请求，达到降级的目的（全局异常处理）
			2、返回NULL
			3、调用mock数据（假数据）---设计：提前约定好数据
			4、调用fallback处理
			
			服务熔断、服务降级
				熔断，降级都是让请求不可达
				熔断更多是考虑方法，降级更多考虑服务
		
		降级的方式：
			1、人工降级
				服务负荷：CPU利用率超过 80%，降级...(采集，监控)
				预案降级：设置服务接口降级级别
			2、自动降级
				故障
				超时
		
			人工降级：如何精确化的控制服务的降级，服务限流---服务治理
				解决方案：通过配置中心来对服务进行治理（降级）
					appolo 配置中心：对配置文件更新是实时感知，通知服务拉取最新的配置信息，更新服务更新内存中的配置信息
					appolo提供可视化的操作界面操作配置中心：比如修改配置文件实现服务降级
					
		
		超时与重试
			nginx
			web容器
			中间件
			数据库
			业务
			ajax超时与重试
			
		压测与预案
			
			
		
		什么是高并发
		
			名词：
				Response Time
				Throughput:吞吐量
				QPS
				UV
				TPS
				DAU
				PV
				IP
		高并发系统设计问题的思考
			双11，抢购，12306
			
		高并发
			技术要做的事：
				JVM优化，架构优化，让程序最优，单词请求从50ms优化到25ms
				
				另一方面就是增加服务器，用更大的集群来处理用户请求
				
			时间
				缓存
				
			容量
				预估
				可以估算：
				服务器：2cpus 4GB --------对这个服务器并发能力估算
				
				前提条件：忽略其他因素的影响（response time，cpu 切换时间），只需要根据内存估算服务器并发能力
				并发：200 QPS	
					静态请求：150 ---- 访问的数据在缓存，不需要读数据库，也就是说不需要把数据放入内存， 一个线程占用1M--2M（经验参考平均值）
					动态请求：50个动态缓存 ------查询数据库，把数据放入内存 ------ 10M（经验参考平均值）
					
					计算：总内存： 150 * 2 + 50 * 10 = 800M
					
					思考：服务器总内存4G，操作系统占用一部分内存，剩下的内存才是服务在使用
						
						800M * 4 = 3.2G（内存） ------200*4 = 800 QPS
						800M * 5 = 4G（内存） ------200*5 = 1000 QPS
						
					2cpus,4GB ----QPS(0,800)----估算值（只考虑内存因素）-----------------实际综合值300（其中还要考虑代码能力的问题，代码烂，rt长）
					4cpus,16GB ----QPS(0,3200)----估算值（只考虑内存因素）---------------实际中和值2000左右（硬件提升，rt更少）
					
				但是实际上不能达到这么多，
					因为，当一个请求来时，执行任务需要时间，执行完了之后还要相应一下，整个过程叫response time
					所以吞吐量要考虑rt，并且还要考虑cpu切换时间
					并发能力影响因素
						1、rt
						2、cpu切换时间
						3、内存
					
					真实结果只能以实际测试结果为准
					
			好的分布式方案（Throughput）:并不能用堆机器的方案来处理
				
				那我们应该做的是，尽量让堆积服务器的效果达到线性增长
				
			如何保证系统的高并发
				服务尽量拆分部署（分布式，SOA，微服务）
				尽量将请求拦截在系统上游（越上游越好）
				读多写少使用缓存（缓存抗读压力）
				浏览器和APP做限速
				站点层：按照uid做限速，做页面缓存
				服务层：按业务做写请求队列控制流量，做数据缓存
				
					浏览器    缓存   70%读请求    ehcache
					
					nginx	  缓存
					
					server	  缓存	  cache（redis）
					
					mysql	  闲庭信步，压力小
					
				具体的解决方案
					缓存（应用级别缓存，http缓存，多级缓存）
					连接池（频繁创建对象，销毁对象，浪费资源）
					异步（异步解耦，用户感知不到过程）
					扩容（增加服务节点：服务器，虚拟机，k8s）
					消息队列（异步）
					
					
				多级缓存应用
					程序内存数据（读写速度） > Redis缓存 > mysql > 磁盘
					单机网络请求（本地请求） > 局域网请求 > 跨机房
					
					优化方案：	把资源放在程序调用最近的地方
						
						浏览器缓存   ehcache 设置过期时间
						CDN缓存
						NGINX缓存
						应用级别的缓存：堆缓存，堆外缓存，技术方案ehcache
						
						所谓缓存，就是让数据离用户更近
						
						例如CPU架构（三级缓存）
						项目也可以设置多级缓存
							堆缓存：不需要序列化
							堆外缓存：需要序列化
							磁盘缓存（存储在本地磁盘）：需要序列化
							以上为程序内部的缓存
							redis:缓存
							mysql：缓存
				
				连接池详情
					连接池的目的：是通过连接池减少频繁的创建连接，释放连接，降低消耗，提升性能（吞吐量）
					连接池：数据库连接，Redis连接池，Http连接池
					技术方案：Apache commons pool2, jedis, druid, dbcp
					是否知道连接池怎么配置？设置多少个队列，设置多少个线程？？
					
					例如：1w QPS 2w TPS 连接池应设置多少？？
					回答：尽量设置大些吧，设置个500吧 ----- 此话是否正确？？
						很明显不正确
					
					这里有一张表
					 条件						线程池设置大小				每隔请求在连接池队列里平均等待时间				执行SQL耗时				总耗时
					 
					 oracle、9600并发			2048							33ms											77ms				110ms
												1024							33ms											56ms				89ms
												96								1ms												2ms					3ms
					
					为什么会出现这种情况？
					
					 首先需要了解程序是如何执行的？？？程序是一个一个的线程。线程要获得执行权限，必须要抢占CPU资源，才能执行程序
					 若连接池太多，会造成频繁的CPU上下文切换，消耗了一定的时间，导致执行性能下降
					 
					 线程池的数字到底应该设置多大？
						需要考虑两个因素
							业务类型：
								CPU计算密集型  --- 业务处理
								IO密集型 --- 数据存取
								
						公式：
							线程数 = Ncpus/(1-阻塞系数)
							
							注：阻塞系数 = w(线程阻塞时间)/(w+c)(线程计算时间)----------------w:wait   c:calculate
								io密集型：阻塞时间 > 计算时间
								cpu密集型：计算时间 > 阻塞时间
								
								对于cpu密集型，阻塞系数非常小。无穷接近于0  所以线程数 = Ncpus / 1 = N ，但是经验上一般设置为N+1
									理想状态，线程池线程数为什么要和CPU的核心数相等？
									因为理想状态是，N个线程过来后，把N个任务分配给N个不同的cpu核心，不存在抢占资源的情况。
									N+1的设计是为了在某个线程出现异常的时候，能快速定位。
									
								对于io密集型，阻塞系数非常大（小于1，看公式）无穷接近于1，因此，如果是IO密集型的任务，
								线程池的线程数应该设置得更多一些
								例如：IO密集型阻塞系数 = 0.9
									线程数 = N / (1 - 0.9) = 10N
						
						
						线程池：
							并发编程：使用多线程技术，提供任务的处理速度（避免频繁创建对象和销毁对象，消耗性能）
							
							Java提供并发编程：（JUC）
								ExecutorService 实现线程池构建。（1、ThreadPoolExecutor   2、ScheduledThreadPoolExecutor 3、ForkJoinPool（注意区别（为每个线程创建任务队列）））
								
								Executors.
								
								参数：
									看书
									
						Tomcat线程池
							
							
						线程数计算
						
						
						
						异步并发
							
						
						Futrure
						Callback ---- 开启几个父线程，异步处理后台任务
						CompletableFutrue
								
							
							
						
						
				
				
					
					
					
					
		
		

