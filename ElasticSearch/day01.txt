Jack Hu
开篇几个问题
	问题1：大规模数据如何检索？--PB = 1024TB,TB = 1024GB量级---吞吐量，RT(response time)
		方案1：关系型数据库存储数据，实现数据的检索------无法实现（速度慢，IO瓶颈的问题----不适合作为大规模数据检索的工具）
		方案2：nosql数据库（考虑因素：内存----查询速度快）------不适合（nosql无法实现关键词检索）
		方案3：hadoop（数据分析） + hbase(nosql) + hive------无法实现
		思考：以上方案不能实现大规模数据检索，主要思考：性能，是否能实现关键词检索的问题？？
		
		自己设计：
			1）数据放入内存： ----- 考虑性能问题：RT
			2）数据压缩 ----------- 传输数据的量级就变小，RT相应时间变短
			3）索引			------- 查询数据先检索索引，再查询对象，RT变短
			4）多线程
			5）顺序存储
			并发多线程是必备的
			
			
	完全把数据放入内存怎么样？
		按每个节点96GB内存计算，在内存完全装满的数据的情况下 ，我们需要的机器是：1PB=1024T = 1048576G
		
		节点数 = 1048576 / 96  = 10922
		
		实际上还要考虑数据备份，所以要用10922 * 2 
		所以最少需要2万台以上的服务器
		
		所以很明显，这样的设计非常不靠谱
	
	
	设计自己的大规模数据检索的搜索软件
		1）数据放入内存： ----- 考虑性能问题：RT-------------经常检索的数据，刚添加的数据（一部分在内存里面）
		2）数据压缩 ----------- 传输数据的量级就变小，RT相应时间变短
		3）索引			------- 查询数据先检索索引，再查询对象，RT变短
		4）多线程
		5）顺序存储
		
	
	
	问题2：什么是大规模数据检索（全文检索）
		基本概念：对非结构化数据/结构化数据这种数据先建立**索引**，在对**索引**进行搜索**文档**的过程就叫全文索引（Full-text-Serch）
		通俗易懂的解释：把关键词 和 文档中 词语进行匹配，配对成功，就表示此文档是我们需要检索的文档，有匹配度得分
			
		
			非结构化数据：没有固定格式的数据（html,word,excel....）----没有固定长度，没有固定的约束，没有描述性信息，散列数据
			结构化数据：有固定的格式的数据（数据库数据）-----有固定长度（varchar(50)），字段类型、描述修饰数据
			
		搜索算法：倒排索引法
			
			顺序扫描法：
				例如：
					词典
					没有目录---查询一个词语，只能从第一页开始查询，一页一页的开始查询，直到查询到结果为止，查询非常慢
				软件：数据库（全表扫描），加索引后会改善改善
				
			倒排索引法
				例如：
					词典
					有目录-----查询一个词语，先查询目录，根据目录定位到词语所在的页码
					
			直观的解释：
				静夜思
				床前明月光，疑是地上霜。
				举头望明月，低头思故乡。
				
				id    title
				1	  静夜思
				2     黄鹤楼
				3     静夜思
				
				正想思维：根据ID查询：id = 1;
				
				反向索引的思维
				title			ID
				静夜思			1,3
				黄鹤楼			2
				
				通过关键词查询文档ID：反向索引法
				
				
	问题3：数据库可以建立索引，也可以进行倒排索引搜索，为什么不能使用数据库进行大规模数据检索？
			select * from table where name like '%医疗口罩%';
			
			存在的问题
				1）全表扫描 ---- 速度非常慢
				2）字段中所有的内容都需要挨个匹配---速度非常慢
				3）全文检索的问题，关键词拆分的问题，比如写错了'%口~罩%'，这个时候就无法匹配任何一个结果了
				4）like 模糊查询，不走索引
				综上所述，数据库一定不适合去做全文检索
			
	问题4：什么是索引：
				索引就是对一段文字进行分词拆解后的单词
				举例："使用ES进行全文检索" 对这段文字使用分词器进行拆解"使用"，"ES"，"进行"，"检索"，这一个一个的就是索引的含义
				这里的索引是名词，一个一个的单词就是索引，这里的索引和数据库的索引完全不一样
				
	问题5：什么是文档：
				文档就是一条结构化的数据（数据库的一行数据）
					数据结构的体现：数据库的一行数据）
					JAVA对象的体现，JavaBean（key，value）
	全文检索场景
		搜索引擎
		站内搜索
		系统文件搜索
		
		
	全文检索相关技术
		1、Lucene：如果使用该技术实现，需要对Lucene的API和底层原理非常了解，而且需要编写大量的java代码
			lucene制定java搜索API接口规范----扩展（搜索，分词，索引库）
			lucene只是一套API，但是不是一套产品，可以使用Lucene开发一套搜索产品，但是非常难以解决
		2、Solr：使用java实现的一个web应用，可以使用rest方式的http请求，进行远程API的调用
			solr是一个项目，只需要把此项目部署到服务器，就可以实现搜索，solr底层就是lucene
		3、ElasticSearch(ES)：可以使用rest方式的http请求，进行远程API的调用
			分布式搜索引擎产品，这个产品也是一个线程，只需要把es部署到服务器，就可以实现。底层也是使用lucene实现的
			
	问题6：到底应该使用solr还是使用elastic search
		根据需求来判定：
			对单纯已有数据（数据不是实时，规模不是太大的（达到TB级别就该考虑用es了））进行搜索时，Solr更快
				Solr比较适合数据量较小的项目
				同时也比较适合数据固定的项目
			当实时建立索引时，Solr会产生IO阻塞，查询性能较差，Elasticsearch具有明显的优势
				solr不适合有实时数据写入的场景
				es比较适合实时数据写入场景（电商，百度）
			随着数据量的增加，Solr的搜索效率会变得更低，而ElasticSearch的性能没有明显变化
			
	大型互联网公司，实际生产环境测试，将solr转到es以后平均查询速度有了50倍的提升
	
	
	
	全文检索的流程：
		
	
	
		索引库是怎么产生的？？？
			1、全文检索，从哪儿进行搜索，数据从哪里来？
				索引库可以和es服务在一起，使用本地文件系统进行存储
				也可以使用第三方文件系统进行存储
			
			2、如何实现关键词检索？？
				思考：1、请你背诵包含“月”子的诗词
					   2、请求背诵包含静夜思的诗词
					   
					   通过索引，建立与文档的对应关系
					   
		创建索引库的过程：
			详细的探讨，索引库创建的流程，深入理解索引库建立的过程
			
				采集数据：数据来源，网页，数据库，文件系统，手动输入
				
				数据建模：把非结构化的数据变成结构化的数据
					把网页数据变成
						id,title,content,url,data---------------->数据建模完成
					把网页建成一个一个字段
				
				把建模好的数据变成文档对象
					文档对象：document
					
				建立索引
				索引文档存储
					索引，使用中文分词器进行分词建立索引库
					文档
				
				将建立好的索引和索引词典和文档统统写入到索引库里
				
				
		既然索引库的数据有了，现在需要探讨索引库的数据如何去检索
		
			
			
		
	
	
		
		
kibana

自带的简单分词器
		POST /_analyze
{
  "analyzer": "simple",//自带分词器
  "text": "我是一个程序员，咿呀咿呀哟！"
}

效果
{
  "tokens" : [
    {
      "token" : "我是一个程序员",
      "start_offset" : 0,
      "end_offset" : 7,
      "type" : "word",
      "position" : 0
    },
    {
      "token" : "咿呀咿呀哟",
      "start_offset" : 8,
      "end_offset" : 13,
      "type" : "word",
      "position" : 1
    }
  ]
}

ik_smart
POST /_analyze
{
  "analyzer": "ik_smart",
  "text": "我是一个程序员，咿呀咿呀哟！"
}
{
  "tokens" : [
    {
      "token" : "我",
      "start_offset" : 0,
      "end_offset" : 1,
      "type" : "CN_CHAR",
      "position" : 0
    },
    {
      "token" : "是",
      "start_offset" : 1,
      "end_offset" : 2,
      "type" : "CN_CHAR",
      "position" : 1
    },
    {
      "token" : "一个",
      "start_offset" : 2,
      "end_offset" : 4,
      "type" : "CN_WORD",
      "position" : 2
    },
    {
      "token" : "程序员",
      "start_offset" : 4,
      "end_offset" : 7,
      "type" : "CN_WORD",
      "position" : 3
    },
    {
      "token" : "咿呀",
      "start_offset" : 8,
      "end_offset" : 10,
      "type" : "CN_WORD",
      "position" : 4
    },
    {
      "token" : "咿呀",
      "start_offset" : 10,
      "end_offset" : 12,
      "type" : "CN_WORD",
      "position" : 5
    },
    {
      "token" : "哟",
      "start_offset" : 12,
      "end_offset" : 13,
      "type" : "CN_CHAR",
      "position" : 6
    }
  ]
}
ik_max_word


		
		
		
		
		
		
	当系统数据量上了10亿、100亿条的时候，我们在做系统架构的时候通常会从以下角度去考虑：
	
	1）用什么数据库好？（MySQL、Oracle、sybase、达梦、神通、MongoDB、Hbase）
	2）如何解决单点故障；（lvs、F5、A10、Zookeeper、MQ）
	3）如何保证数据安全性；（热备，冷备，异地多活）
	4）如何解决检索难题;(数据库代理中间件：mysql-proxy、Cobar、MaxScale等)
	5）如何解决统计分析问题（离线，近实时）